import cv2
import mediapipe as mp
import tkinter as tk
from tkinter import messagebox, simpledialog
import numpy as np
import os
import threading
import time
import pickle
from sklearn.metrics.pairwise import cosine_similarity


class ImprovedFaceAlert:
    def __init__(self):
        # MediaPipe Setup
        self.mp_face_detection = mp.solutions.face_detection
        self.mp_face_mesh = mp.solutions.face_mesh
        self.mp_drawing = mp.solutions.drawing_utils

        # ErhÃ¶hte Empfindlichkeit
        self.face_detection = self.mp_face_detection.FaceDetection(
            model_selection=1, min_detection_confidence=0.5)  # Niedrigere Schwelle
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=False, max_num_faces=5,
            refine_landmarks=True, min_detection_confidence=0.5)

        # Face Recognition Setup - Mehrere Samples pro Person
        self.known_faces = {}  # Dict: name -> [liste von features]
        self.video_capture = cv2.VideoCapture(0)
        self.alert_cooldown = 0

        # Verbesserte Parameter
        self.recognition_threshold = 0.85 # Cosine Similarity Schwelle
        self.min_samples_per_person = 3  # Mindestens 3 Samples pro Person

        self.load_known_faces()

    def extract_enhanced_features(self, landmarks, frame_shape):
        """Verbesserte Feature-Extraktion mit mehr Details"""
        if not landmarks:
            return None

        h, w = frame_shape[:2]

        # Alle wichtigen Gesichtspunkte (mehr als vorher)
        key_points = [
            # Gesichtskontur
            10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288,
            # Augenbrauen
            70, 63, 105, 66, 107, 55, 65, 52, 53, 46,
            # Augen (links und rechts)
            33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246,
            362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398,
            # Nase
            1, 2, 5, 4, 6, 19, 20, 94, 125, 141, 235, 236, 3, 51, 48, 115, 131, 134, 102, 49, 220, 305, 307, 375, 321,
            308, 324, 318,
            # Mund
            61, 84, 17, 314, 405, 320, 307, 375, 321, 308, 324, 318,
            78, 95, 88, 178, 87, 14, 317, 402, 318, 324,
            # Kinn
            18, 175, 199, 175, 199, 175, 199
        ]

        # Features extrahieren
        features = []

        # 1. Koordinaten der SchlÃ¼sselpunkte
        for point_idx in key_points:
            if point_idx < len(landmarks.landmark):
                landmark = landmarks.landmark[point_idx]
                features.extend([landmark.x, landmark.y, landmark.z])

        # 2. Geometrische VerhÃ¤ltnisse berechnen
        if len(landmarks.landmark) > 300:
            # Augenabstand
            left_eye = landmarks.landmark[33]
            right_eye = landmarks.landmark[362]
            eye_distance = np.sqrt((left_eye.x - right_eye.x) ** 2 + (left_eye.y - right_eye.y) ** 2)

            # Nase zu Mund VerhÃ¤ltnis
            nose_tip = landmarks.landmark[1]
            mouth_center = landmarks.landmark[13]
            nose_mouth_dist = np.sqrt((nose_tip.x - mouth_center.x) ** 2 + (nose_tip.y - mouth_center.y) ** 2)

            # GesichtshÃ¶he vs Breite
            top = landmarks.landmark[10]
            bottom = landmarks.landmark[175]
            left = landmarks.landmark[234]
            right = landmarks.landmark[454]

            face_height = abs(top.y - bottom.y)
            face_width = abs(left.x - right.x)
            face_ratio = face_height / (face_width + 0.001)

            # Geometrische Features hinzufÃ¼gen
            features.extend([eye_distance, nose_mouth_dist, face_ratio])

        return np.array(features)

    def compare_faces_improved(self, features1, features2):
        """Verbesserte Gesichtserkennung mit Cosine Similarity"""
        if features1 is None or features2 is None:
            return 0.0

        # Sicherstellen dass beide gleiche LÃ¤nge haben
        min_len = min(len(features1), len(features2))
        features1 = features1[:min_len]
        features2 = features2[:min_len]

        # Cosine Similarity berechnen (besser als Euklidische Distanz)
        similarity = cosine_similarity([features1], [features2])[0][0]
        return similarity

    def recognize_face(self, current_features):
        """Erkennt Gesicht gegen alle bekannten Personen"""
        if current_features is None:
            return "EINDRINGLING", 0.0

        best_match = "EINDRINGLING"
        best_score = 0.0

        for name, face_samples in self.known_faces.items():
            # Vergleiche mit allen Samples dieser Person
            similarities = []
            for sample_features in face_samples:
                sim = self.compare_faces_improved(current_features, sample_features)
                similarities.append(sim)

            # Nimm den besten Match von allen Samples
            if similarities:
                max_similarity = max(similarities)
                avg_similarity = np.mean(similarities)

                # Gewichteter Score (70% bester Match, 30% Durchschnitt)
                final_score = 0.7 * max_similarity + 0.3 * avg_similarity

                if final_score > best_score and final_score > self.recognition_threshold:
                    best_match = name
                    best_score = final_score

        return best_match, best_score

    def load_known_faces(self):
        """LÃ¤dt bekannte Gesichter"""
        if os.path.exists("improved_faces.pkl"):
            try:
                with open("improved_faces.pkl", "rb") as f:
                    self.known_faces = pickle.load(f)
                print(f"âœ… Geladene Personen: {list(self.known_faces.keys())}")
                for name, samples in self.known_faces.items():
                    print(f"   {name}: {len(samples)} Trainingsbilder")
            except Exception as e:
                print(f"âŒ Fehler beim Laden: {e}")

        if not self.known_faces:
            print("ğŸ¤· Keine bekannten Gesichter gefunden!")

    def save_known_faces(self):
        """Speichert bekannte Gesichter"""
        with open("improved_faces.pkl", "wb") as f:
            pickle.dump(self.known_faces, f)
        print("ğŸ’¾ Gesichter gespeichert!")

    def show_intruder_popup(self):
        """Lustiges Pop-up fÃ¼r Eindringlinge"""

        def popup_thread():
            root = tk.Tk()
            root.withdraw()

            messages = [
                "ğŸš¨ SICHERHEITSALARM! ğŸš¨\nUnbekanntes Gesicht entdeckt!",
                "ğŸ‘® HALT! ğŸ‘®\nWer geht da?!",
                "ğŸ•µï¸ EINDRINGLING! ğŸ•µï¸\nZeig deine ID!",
                "ğŸš« STOPP! ğŸš«\nDu gehÃ¶rst nicht hier her!",
                "ğŸ‘½ ALIEN ALERT! ğŸ‘½\nBist du von der Erde?",
                "ğŸ¤– BEEP BEEP! ğŸ¤–\nSicherheitssystem aktiviert!",
                "ğŸ­ UNBEKANNT! ğŸ­\nBist du verkleidet?",
                "ğŸ” GESICHT SCAN FEHLGESCHLAGEN! ğŸ”\nSind das deine echten Augen?"
            ]

            import random
            message = random.choice(messages)
            messagebox.showwarning("ğŸš¨ SICHERHEITSALARM ğŸš¨", message)
            root.destroy()

        threading.Thread(target=popup_thread, daemon=True).start()

    def capture_multiple_samples(self):
        """Erfasst mehrere Trainingsbilder einer Person"""
        name = None
        root = tk.Tk()
        root.withdraw()
        name = simpledialog.askstring("Name eingeben", "Wie heiÃŸt du?")
        root.destroy()

        if not name:
            return

        print(f"\nğŸ¯ Erfasse Trainingsbilder fÃ¼r {name}")
        print("ğŸ“¸ Bewege dein Gesicht leicht zwischen den Aufnahmen!")
        print("â¸ï¸  DrÃ¼cke SPACE fÃ¼r jede Aufnahme")
        print("âŒ ESC zum Abbrechen")

        if name not in self.known_faces:
            self.known_faces[name] = []

        samples_needed = max(0, self.min_samples_per_person - len(self.known_faces[name]))
        samples_taken = 0

        while samples_taken < samples_needed + 2:  # 2 extra Samples
            ret, frame = self.video_capture.read()
            if not ret:
                break

            frame = cv2.flip(frame, 1)
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # Gesichter erkennen
            results = self.face_mesh.process(rgb_frame)

            if results.multi_face_landmarks:
                for face_landmarks in results.multi_face_landmarks:
                    # Landmarks zeichnen
                    self.mp_drawing.draw_landmarks(
                        frame, face_landmarks, self.mp_face_mesh.FACEMESH_CONTOURS,
                        None, self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1))

                status_text = f"Sample {samples_taken + 1} - DrÃ¼cke SPACE"
                cv2.putText(frame, status_text, (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(frame, f"FÃ¼r {name}", (10, 60),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            else:
                cv2.putText(frame, "Kein Gesicht erkannt!", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

            cv2.imshow('Trainingsbilder aufnehmen', frame)

            key = cv2.waitKey(1) & 0xFF
            if key == ord(' '):  # Space
                if results.multi_face_landmarks:
                    # Features extrahieren
                    features = self.extract_enhanced_features(
                        results.multi_face_landmarks[0], frame.shape)
                    if features is not None:
                        self.known_faces[name].append(features)
                        samples_taken += 1
                        print(f"âœ… Sample {samples_taken} fÃ¼r {name} gespeichert!")

                        if samples_taken >= samples_needed + 2:
                            break

                        time.sleep(0.5)  # Kurze Pause
                else:
                    print("âŒ Kein Gesicht erkannt! Versuche es nochmal.")
            elif key == 27:  # ESC
                break

        cv2.destroyWindow('Trainingsbilder aufnehmen')

        if samples_taken > 0:
            self.save_known_faces()
            print(f"ğŸ‰ {samples_taken} Trainingsbilder fÃ¼r {name} gespeichert!")
            print(f"ğŸ“Š {name} hat jetzt {len(self.known_faces[name])} Trainingsbilder")
        else:
            print("âŒ Keine Trainingsbilder aufgenommen!")

    def run(self):
        """Hauptschleife mit verbesserter Erkennung"""
        print("ğŸš€ Verbesserte Face Recognition Alert gestartet!")
        print("=" * 60)
        print("âŒ¨ï¸  Steuerung:")
        print("   'q' = Beenden")
        print("   'c' = Neues Gesicht trainieren")
        print("   's' = Einstellungen anzeigen")
        print("=" * 60)

        if not self.known_faces:
            response = input("ğŸ¤” MÃ¶chtest du dein Gesicht jetzt trainieren? (j/n): ")
            if response.lower() == 'j':
                self.capture_multiple_samples()

        print("\nğŸ“¹ Kamera gestartet... Viel SpaÃŸ!")

        while True:
            ret, frame = self.video_capture.read()
            if not ret:
                break

            frame = cv2.flip(frame, 1)
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # Gesichter erkennen
            results = self.face_mesh.process(rgb_frame)

            if results.multi_face_landmarks:
                for face_landmarks in results.multi_face_landmarks:
                    # Features extrahieren
                    current_features = self.extract_enhanced_features(face_landmarks, frame.shape)

                    # Gesicht erkennen
                    name, confidence = self.recognize_face(current_features)

                    # Pop-up fÃ¼r Eindringlinge
                    if name == "EINDRINGLING" and time.time() > self.alert_cooldown:
                        self.show_intruder_popup()
                        self.alert_cooldown = time.time() + 5

                    # Gesicht zeichnen
                    color = (0, 255, 0) if name != "EINDRINGLING" else (0, 0, 255)

                    # Bounding Box
                    h, w, _ = frame.shape
                    x_coords = [int(landmark.x * w) for landmark in face_landmarks.landmark]
                    y_coords = [int(landmark.y * h) for landmark in face_landmarks.landmark]

                    x_min, x_max = min(x_coords), max(x_coords)
                    y_min, y_max = min(y_coords), max(y_coords)

                    # Rechteck und Info zeichnen
                    cv2.rectangle(frame, (x_min, y_min), (x_max, y_max + 60), color, 2)
                    cv2.rectangle(frame, (x_min, y_max), (x_max, y_max + 60), color, cv2.FILLED)

                    # Name und Konfidenz anzeigen
                    cv2.putText(frame, name, (x_min + 5, y_max + 20),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                    if name != "EINDRINGLING":
                        confidence_text = f"{confidence:.1%}"
                        cv2.putText(frame, confidence_text, (x_min + 5, y_max + 45),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            # Status anzeigen
            total_people = len(self.known_faces)
            total_samples = sum(len(samples) for samples in self.known_faces.values())
            status = f"Personen: {total_people} | Trainingsbilder: {total_samples}"
            cv2.putText(frame, status, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            # Schwelle anzeigen
            threshold_text = f"Schwelle: {self.recognition_threshold:.0%}"
            cv2.putText(frame, threshold_text, (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            cv2.imshow('ğŸš€ Verbesserte Face Recognition', frame)

            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('c'):
                self.capture_multiple_samples()
            elif key == ord('s'):
                self.show_settings()

        self.video_capture.release()
        cv2.destroyAllWindows()

    def show_settings(self):
        """Zeigt aktuelle Einstellungen"""
        print("\n" + "=" * 50)
        print("âš™ï¸  AKTUELLE EINSTELLUNGEN")
        print("=" * 50)
        print(f"ğŸ¯ Erkennungsschwelle: {self.recognition_threshold:.0%}")
        print(f"ğŸ“¸ Min. Trainingsbilder: {self.min_samples_per_person}")
        print(f"ğŸ‘¥ Bekannte Personen: {len(self.known_faces)}")
        for name, samples in self.known_faces.items():
            print(f"   - {name}: {len(samples)} Trainingsbilder")
        print("=" * 50 + "\n")


if __name__ == "__main__":
    # Sklearn fÃ¼r Cosine Similarity installieren falls nÃ¶tig
    try:
        from sklearn.metrics.pairwise import cosine_similarity
    except ImportError:
        print("âŒ sklearn nicht gefunden!")
        print("ğŸ“¦ Installiere: pip install scikit-learn")
        exit(1)

    app = ImprovedFaceAlert()
    app.run()